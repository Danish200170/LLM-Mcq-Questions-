{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_openai langchain langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Generate {number_of_qs} multiple choice questions for a quiz on the topic of {topic}. Each question should have 4 possible answers, with one correct answer. The questions should be of medium difficulty. The response should json supported. Think step by step and don't send an incomplete response.\")\n",
    "\n",
    "class MCQQuestion(BaseModel):\n",
    "    \"\"\" Response format for a multiple choice question \"\"\"\n",
    "    question: str = Field(description='The question text')\n",
    "    answers: list[str] = Field(description='A list of 4 possible answers')\n",
    "    correct_answer: str = Field(description='The correct answer')\n",
    "\n",
    "class MCQQuestions(BaseModel):\n",
    "    \"\"\" A list of multiple choice questions \"\"\"\n",
    "    list_of_questions: list[MCQQuestion] = Field(\n",
    "        description='A list of multiple choice questions')\n",
    "\n",
    "llm = chat.with_structured_output(MCQQuestions)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = json.loads(open(\"topics.json\").read())['topics']\n",
    "\n",
    "all_questions = {}\n",
    "for topic in topics:\n",
    "    response = chain.invoke({\"number_of_qs\": 50, \"topic\": topic})\n",
    "    all_questions[topic] = response.list_of_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for topic, questions_list in all_questions.items():\n",
    "    for question in questions_list:\n",
    "        questions.append({\n",
    "            'topic': topic,\n",
    "            'question': question.question,\n",
    "            'answers': question.answers,\n",
    "            'correct_answer': question.correct_answer\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(questions)\n",
    "df.to_csv(\"mcq_questions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
